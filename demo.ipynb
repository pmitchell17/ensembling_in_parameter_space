{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling Neural Networks in Parameter Space\n",
    "\n",
    "## Ensembling in function space (DeepEnsembles)\n",
    "\n",
    "In contrast to classical machine learning methods that are typically ensembled using methods such as bagging and boosting, neural networks are typically ensembled by averaging over the outputs of M models. These ensembles are referred to as \"DeepEnsembles\". We demonstrate this on the FMNIST dataset.\n",
    "\n",
    "### MLP model training\n",
    "\n",
    "We first train different fully-connected MLP (multi-layer-perceptron) models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=0.576539\n",
      "Epoch 1, loss=0.518139\n",
      "Epoch 2, loss=0.383257\n",
      "Epoch 3, loss=0.356229\n",
      "Epoch 4, loss=0.297822\n",
      "Epoch 5, loss=0.295248\n",
      "Epoch 6, loss=0.339013\n",
      "Epoch 7, loss=0.278767\n",
      "Epoch 8, loss=0.333586\n",
      "Epoch 9, loss=0.332020\n",
      "Epoch 10, loss=0.274140\n",
      "Epoch 11, loss=0.380642\n",
      "Epoch 12, loss=0.286756\n",
      "Epoch 13, loss=0.172852\n",
      "Epoch 14, loss=0.283777\n",
      "Epoch 15, loss=0.341362\n",
      "Epoch 16, loss=0.305385\n",
      "Epoch 17, loss=0.244607\n",
      "Epoch 18, loss=0.183814\n",
      "Epoch 19, loss=0.325876\n",
      "Epoch 0, loss=0.341201\n",
      "Epoch 1, loss=0.367920\n",
      "Epoch 2, loss=0.333906\n",
      "Epoch 3, loss=0.399982\n",
      "Epoch 4, loss=0.259520\n",
      "Epoch 5, loss=0.434693\n",
      "Epoch 6, loss=0.451741\n",
      "Epoch 7, loss=0.202714\n",
      "Epoch 8, loss=0.384630\n",
      "Epoch 9, loss=0.257044\n",
      "Epoch 10, loss=0.231636\n",
      "Epoch 11, loss=0.362356\n",
      "Epoch 12, loss=0.216920\n",
      "Epoch 13, loss=0.315052\n",
      "Epoch 14, loss=0.253563\n",
      "Epoch 15, loss=0.262427\n",
      "Epoch 16, loss=0.272994\n",
      "Epoch 17, loss=0.319944\n",
      "Epoch 18, loss=0.239534\n",
      "Epoch 19, loss=0.191490\n",
      "Epoch 0, loss=0.455205\n",
      "Epoch 1, loss=0.276931\n",
      "Epoch 2, loss=0.562649\n",
      "Epoch 3, loss=0.352670\n",
      "Epoch 4, loss=0.431263\n",
      "Epoch 5, loss=0.525783\n",
      "Epoch 6, loss=0.287524\n",
      "Epoch 7, loss=0.294282\n",
      "Epoch 8, loss=0.263635\n",
      "Epoch 9, loss=0.292250\n",
      "Epoch 10, loss=0.194984\n",
      "Epoch 11, loss=0.346068\n",
      "Epoch 12, loss=0.379704\n",
      "Epoch 13, loss=0.275308\n",
      "Epoch 14, loss=0.154080\n",
      "Epoch 15, loss=0.193920\n",
      "Epoch 16, loss=0.153166\n",
      "Epoch 17, loss=0.186981\n",
      "Epoch 18, loss=0.318584\n",
      "Epoch 19, loss=0.323376\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from models.mlp import MLP\n",
    "from training.dataloaders import fmnist_train_loader\n",
    "from training.trainer import Trainer\n",
    "\n",
    "for model_index in range(3):\n",
    "    #MLP with two layers, 10 outputs\n",
    "    model = MLP([(28*28, 512),(512, 10)])\n",
    "    \n",
    "    optimizer = SGD(params=model.parameters(), lr=0.1, weight_decay=1e-5, momentum=0.9)\n",
    "\n",
    "    trainer = Trainer(\n",
    "            model=model,\n",
    "            dataloader=fmnist_train_loader,\n",
    "            optimizer=optimizer,\n",
    "            lr_scheduler=CosineAnnealingLR,\n",
    "            criterion=nn.CrossEntropyLoss(),\n",
    "            num_epochs=20\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "    torch.save(trainer.model.state_dict(), f'trained_models/mlp/mlp_{model_index}.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP vs. DeepEnsemble Accuracy\n",
    "\n",
    "We first evaluate the accuracy of each of the MLP models. We then compare this to a DeepEnsemble, in which we make a prediction by averaging over the outputs of the models. Hence the output of a DeepEnsemble composed of 3 MLP models (model_A, model_B, model_C) given an input is:\n",
    "\n",
    "DeepEnsemble(input) = (model_A(input) + model_B(input) + model_C(input)) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy model: mlp_0 is 87.97\n",
      "Accuracy model: mlp_1 is 84.28\n",
      "Accuracy model: mlp_2 is 87.3\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from evaluation.evaluator import Evaluator\n",
    "from models.deep_ensemble import DeepEnsemble\n",
    "from models.mlp import MLP\n",
    "from training.dataloaders import fmnist_test_loader\n",
    "\n",
    "models = []\n",
    "names = []\n",
    "for filename in os.listdir('trained_models/mlp'):\n",
    "    model = MLP(in_out_units=[(28*28, 512),(512, 10)])\n",
    "    model.load_state_dict(torch.load(os.path.join('trained_models/mlp', filename)))\n",
    "    models.append(model)\n",
    "    names.append(filename[0:-4])\n",
    "\n",
    "for model_index, model in enumerate(models):\n",
    "    evaluator = Evaluator(test_loader=fmnist_test_loader)\n",
    "    accuracy = evaluator.evaluate(model)\n",
    "    print(f'Accuracy model: {names[model_index]} is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy DeepEnsemble is 88.54\n"
     ]
    }
   ],
   "source": [
    "deep_ensemble = DeepEnsemble(models)\n",
    "evaluator = Evaluator(test_loader=fmnist_test_loader)\n",
    "accuracy = evaluator.evaluate(deep_ensemble)\n",
    "\n",
    "print(f'Accuracy DeepEnsemble is {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the DeepEnsemble has larger accuracy relative to the 3 MLP models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawbacks of DeepEnsembles\n",
    "\n",
    "Although DeepEnsembles show coniderable accuracy increases and are more effective than classical ensembling methods such as bagging and boosting, they do suffer from considerable drawbacks. Namely that a DeepEnsemble requires storing M models and M forward passes at inference time (as we are averaging over the outputs of each model). Such large storage and computational costs are often prohibitive. For this reason other neural network methods have been developed to overcome the computational constraints. One of these methods is Knowledge Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Distillation\n",
    "\n",
    "Knowledge distillation is not limited to the context of ensembles, although ensembles are an ideal example of their application. The core idea behind knowledge distillation is to train a smaller student model on the soft labels of a larger teacher model, rather than on hard training labels. The central idea is that the output distribution of a teacher model is more informative than hard labels, as the output distribution includes information about inter-class similarities. In order to match the output distribution of the teacher model, the student is model is trained using a Kullback-Leibler Divergence loss, which is minimized if the two output distributions are equal. Although, the central idea of Knowledge Distillation is the idea of matching the soft labels of a teacher, usually a combination of soft-labels and hard-labels are used in the loss function. \n",
    "\n",
    "In terms of ensemble learning, a single MLP model (student) is trained to match the output distribution of a DeepEnsemble (teacher). The trained model is more accuracte relative to an MLP model trained only on hard labels and the computational drawbacks of DeepEnsembles are overcome.\n",
    "\n",
    "## Training a knowledge distillation model\n",
    "\n",
    "We train a MLP model with the following loss function:\n",
    "\n",
    "LOSS = 0.5 * KD_LOSS + 0.5 * CE_LOSS\n",
    "\n",
    "where KD_LOSS is Kullback-Leibler Divergence and CE_LOSS is CrossEntropy Loss. The teacher model in the KD_LOSS calculation is a DeepEnsemble of 3 MLP models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\phili\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=0.387560\n",
      "Epoch 1, loss=0.318417\n",
      "Epoch 2, loss=0.321921\n",
      "Epoch 3, loss=0.250921\n",
      "Epoch 4, loss=0.219727\n",
      "Epoch 5, loss=0.173021\n",
      "Epoch 6, loss=0.105502\n",
      "Epoch 7, loss=0.176600\n",
      "Epoch 8, loss=0.136716\n",
      "Epoch 9, loss=0.277662\n",
      "Epoch 10, loss=0.160992\n",
      "Epoch 11, loss=0.123629\n",
      "Epoch 12, loss=0.213426\n",
      "Epoch 13, loss=0.147771\n",
      "Epoch 14, loss=0.168722\n",
      "Epoch 15, loss=0.127819\n",
      "Epoch 16, loss=0.139021\n",
      "Epoch 17, loss=0.152080\n",
      "Epoch 18, loss=0.159721\n",
      "Epoch 19, loss=0.114576\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from loss.knowledge_distillation_loss import KDLoss\n",
    "from models.deep_ensemble import DeepEnsemble\n",
    "from models.mlp import MLP\n",
    "from training.dataloaders import fmnist_train_loader\n",
    "from training.trainer import Trainer\n",
    "\n",
    "#MLP with two layers, 10 outputs\n",
    "model = MLP([(28*28, 512),(512, 10)])\n",
    "    \n",
    "optimizer = SGD(params=model.parameters(), lr=0.1, weight_decay=1e-5, momentum=0.9)\n",
    "\n",
    "deep_ensemble = DeepEnsemble(models)\n",
    "kd_loss = KDLoss(deep_ensemble=deep_ensemble, alpha=.5, temp=3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    dataloader=fmnist_train_loader,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=CosineAnnealingLR,\n",
    "    criterion=kd_loss,\n",
    "    num_epochs=20\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "torch.save(trainer.model.state_dict(), f'trained_models/kd/kd_0.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Distillation Accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Knowledge Distillation Model: is 88.81\n"
     ]
    }
   ],
   "source": [
    "model = MLP(in_out_units=[(28*28, 512),(512, 10)])\n",
    "model.load_state_dict(torch.load('trained_models/kd/kd_0.pth'))\n",
    "\n",
    "evaluator = Evaluator(test_loader=fmnist_test_loader)\n",
    "accuracy = evaluator.evaluate(model)\n",
    "print(f'Accuracy Knowledge Distillation Model: is {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given models, knowledge distillation outperforms the DeepEnsemble in terms of accuracy (88.81 vs. 88.54). Typically, a DeepEnsemble will outperform knowledge distillation in terms of accuracy, especially for larger ensemble sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averaging in Parameter Space (PermAVG)\n",
    "\n",
    "We propose a new neural network ensembling method in which we average in parameter space rather than in function space. In other words, instead of averaging over the outputs of M models, we average over the weights of each the M models, to create a single model. In this way we have overcome the need to store M models and M forward passes at inference time. In this way the method would be computationally equivalent to Knowledge Distillation. However, naively averaging over the weights of M models leads to near-random accuracy and therefore is not a promising method. Therefore, we propose to learn the optimal permutation of the weights, such that the average of the M models is optimal. \n",
    "\n",
    "## Naive Averaging\n",
    "\n",
    "We first demonstrate the low accuracy of naively averaging over the weights of M models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Naive Weight Average is 76.06\n"
     ]
    }
   ],
   "source": [
    "from models.perm_avg import PermAVG\n",
    "\n",
    "naive_ensemble = PermAVG(models=models, naive=True)\n",
    "evaluator = Evaluator(test_loader=fmnist_test_loader)\n",
    "accuracy = evaluator.evaluate(naive_ensemble)\n",
    "\n",
    "print(f'Accuracy Naive Weight Average is {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that naively averaging over the weights lead to poor accuracy. The accuracy is lower than any of the individual MLP models. As the size of the ensemble grows the accuracy will continue to decrease until a near-random accuracy is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PermAVG\n",
    "\n",
    "We now train a PermAVG model to learn the optimal permutations such that the average of the M models is optimal. Note that we are not actually learning permutation matrices as these are discrete and unsuited for gradient-based optimization but Doubly-Stochastic-Matrices (DSM), which is a continuous relaxation of permutation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "perm_avg = PermAVG(models=models, naive=False)\n",
    "\n",
    "optimizer = Adam(params=list(perm_avg.param_matrices.values()), lr=0.1)\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=perm_avg,\n",
    "        dataloader=fmnist_train_loader,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=CosineAnnealingLR,\n",
    "        criterion=nn.CrossEntropyLoss(),\n",
    "        num_epochs=20\n",
    ")\n",
    "trainer.train()\n",
    "perm_avg_mlp = trainer.model.export()\n",
    "torch.save(perm_avg_mlp.state_dict(), f'trained_models/perm_avg/perm_avg_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_avg_mlp = MLP(in_out_units=[(28*28, 512),(512, 10)])\n",
    "perm_avg_mlp.load_state_dict(torch.load('trained_models/perm_avg/perm_avg_0.pth'))\n",
    "\n",
    "evaluator = Evaluator(test_loader=fmnist_test_loader)\n",
    "accuracy = evaluator.evaluate(perm_avg_mlp)\n",
    "print(f'Accuracy PermAVG: is {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MLP(\n",
       "   (linears): ModuleList(\n",
       "     (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "     (1): Linear(in_features=512, out_features=10, bias=True)\n",
       "   )\n",
       "   (relu): ReLU()\n",
       " ),\n",
       " MLP(\n",
       "   (linears): ModuleList(\n",
       "     (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "     (1): Linear(in_features=512, out_features=10, bias=True)\n",
       "   )\n",
       "   (relu): ReLU()\n",
       " ),\n",
       " MLP(\n",
       "   (linears): ModuleList(\n",
       "     (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "     (1): Linear(in_features=512, out_features=10, bias=True)\n",
       "   )\n",
       "   (relu): ReLU()\n",
       " )]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2561557971.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [9]\u001b[1;36m\u001b[0m\n\u001b[1;33m    Learned permutation visualization\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Learned permutation visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
